get_ipython().getoutput("pip install -qU langchain langchain-core langchain-community langchain-openai")
get_ipython().getoutput("pip install -qU qdrant-client")
get_ipython().getoutput("pip install -qU tiktoken pymupdf")
get_ipython().getoutput("pip install beautifulsoup4")
get_ipython().getoutput("pip install openai")


import os
import getpass

os.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")


from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate


openai_chat_model = ChatOpenAI(model="gpt-3.5-turbo")

system_template = "You are helpful assistant who helps \
international student navigate OPT (Optional Practical Training)"

human_template = "{content}"

chat_prompt = ChatPromptTemplate.from_messages([
    ("system", system_template),
    ("human", human_template)
])





import requests
from bs4 import BeautifulSoup

URL = "https://isss.umn.edu/fstudents/employment/opt/basics"
page = requests.get(URL)

soup = BeautifulSoup(page.content, "html.parser")


contents = soup.find(id = "content")
field_item = contents.find_all("div", class_= "field__item")








from openai import OpenAI

client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])


prompt = """
Remove unnecessary html tags and only extract important information from the html provided"
"""


completion = client.chat.completions.create(
    model="gpt-3.5-turbo", 
    messages=[
    {"role": "system", "content": "You are helpful assistant who helps \
        international student navigate OPT (Optional Practical Training)"},
    {"role": "user", "content": content}
  ]
)


p_elements = []
li_elements = []


import tiktoken
from langchain.text_splitter import RecursiveCharacterTextSplitter


enc = tiktoken.encoding_for_model("gpt-3.5-turbo")


from operator import itemgetter
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough

retrieval_augmented_qa_chain = (
    {"context": itemgetter("question") | qdrant_retriever, 
     "question": itemgetter("question")}
    | RunnablePassthrough.assign(context=itemgetter("context"))
    | {"response": rag_prompt | openai_chat_model, 
       "context": itemgetter("context")}
}
